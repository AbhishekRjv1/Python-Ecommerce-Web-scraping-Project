{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of proxies available are :  158\n",
      "\n",
      "\n",
      "\n",
      "<Response [200]> 194.233.69.90:443  | Works  \n",
      "\n",
      "\n",
      "\n",
      "<Response [200]> 27.79.131.31:4003  | Works  \n",
      "\n",
      "\n",
      "\n",
      "<Response [200]> 103.214.202.105:8080  | Works  \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this is the program used to get proxies and check response on a website\n",
    "# this program selects the proxies that work and returns them\n",
    "\n",
    "\n",
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import random\n",
    "import concurrent.futures\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#get the list of free proxies\n",
    "def getProxies():\n",
    "    r = requests.get('https://free-proxy-list.net/')\n",
    "    soup = bs(r.content, 'html.parser')\n",
    "    table = soup.find('tbody')\n",
    "    proxies = []\n",
    "    for row in table:\n",
    "        if row.find_all('td')[4].text =='elite proxy':\n",
    "            proxy = ':'.join([row.find_all('td')[0].text, row.find_all('td')[1].text])\n",
    "            proxies.append(proxy)\n",
    "        else:\n",
    "            pass\n",
    "    return proxies\n",
    "\n",
    "\n",
    "proxies = getProxies()\n",
    "print(\"Number of proxies available are : \", len(proxies))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "with open('proxylist.csv', 'w', newline=\"\") as f:\n",
    "    thewriter = csv.writer(f)\n",
    "    for i in proxies:\n",
    "        thewriter.writerow([i])\n",
    "\n",
    "        \n",
    "def extract(proxy):\n",
    "    \n",
    "    url = \"https://www.thewhiskyexchange.com/p/43320/renegade-gin?suggested=true&source=featurepage&type=archive\"\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:80.0) Gecko/20100101 Firefox/80.0'}\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        r = requests.get(url, headers=headers, proxies={'http' : proxy,'https': proxy}, timeout=2)\n",
    "        \n",
    "        if r.status_code == 200:\n",
    "            print(r, proxy, ' | Works  \\n\\n\\n')\n",
    "            \n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return proxy\n",
    "\n",
    "\n",
    "#opens a csv file of proxies and prints out the ones that work with the url in the extract function\n",
    "\n",
    "\n",
    "proxylist = []\n",
    "\n",
    "with open('proxylist.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        proxylist.append(row[0])\n",
    "\n",
    "\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        executor.map(extract, proxylist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
