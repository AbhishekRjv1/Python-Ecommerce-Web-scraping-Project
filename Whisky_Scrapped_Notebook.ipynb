{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install requests\n",
    "#!pip3 install bs4\n",
    "#!pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12bae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f73b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link(link):\n",
    "    \n",
    "    '''\n",
    "    Input: \n",
    "    url: The link which has to be scrapped\n",
    "    \n",
    "    Output: \n",
    "    Dictionary with the scrapped values\n",
    "    \n",
    "    Function Definition: \n",
    "    The following function takes in a url and scrapes required values from the website and converts them \n",
    "    to a dictionary\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ## Defining the user agent\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    ## Requesting data from link\n",
    "    r = requests.get(link)\n",
    "    \n",
    "\n",
    "    ## Getting data from link\n",
    "    soup = bs(r.content, 'lxml')\n",
    "    \n",
    "    \n",
    "    ## Try block for getting values\n",
    "    try:\n",
    "        name = (soup.find('h1', class_='product-main__name').text.strip())\n",
    "        per = soup.find('p', class_='product-main__data').text.strip().strip(\"%\").strip(\"70cl /\")\n",
    "        star = soup.find('span', class_='review-overview__rating star-rating star-rating--50').text.strip()\n",
    "        no_review = soup.find('span', class_='review-overview__count').text.strip().strip(\"()\").strip(\"Reviews\").strip(\"\\xa0\")\n",
    "        available = soup.find('p', class_='product-action__stock-flag').text.strip().strip(\"Stock\")\n",
    "        price = soup.find('p', class_='product-action__price').text.strip()\n",
    "        ex_vat = soup.find('p', class_='product-action__vat-price').text.strip().strip(\"ex VAT\")\n",
    "        price_litre = soup.find('p', class_='product-action__unit-price').text.strip().strip(\"()\").strip(\"per litre\")\n",
    "        mul_disc = soup.find('span', class_='product-multibuy__save-price').text.strip(\"Save\").strip()\n",
    "     \n",
    "    ## Except block for missing values\n",
    "    except:\n",
    "        name=\"nil\"\n",
    "        per=\"nil\"\n",
    "        star=\"nil\"\n",
    "        no_review=\"nil\"\n",
    "        available=\"nil\"\n",
    "        price=\"nil\"\n",
    "        ex_vat=\"nil\"\n",
    "        price_litre=\"nil\"\n",
    "        mul_disc=\"nil\"\n",
    "        \n",
    "    ## Converting the scraped values to a dictionary   \n",
    "    whisky = {\n",
    "        \"name\" : name,\n",
    "        \"percent\" : per,\n",
    "        \"star\" : star,\n",
    "        \"no_review\" : no_review,\n",
    "        \"available\" : available,\n",
    "        \"price\" : price,\n",
    "        \"ex_vat\" : ex_vat,\n",
    "        \"price_litre\" : price_litre,\n",
    "        \"mul_disc\" : mul_disc\n",
    "\n",
    "    }\n",
    "\n",
    "    return whisky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ec4416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_df_to_csv(df,path_directory):\n",
    "    \n",
    "    '''\n",
    "    Input:\n",
    "    df: Takes in a dataframe which has to be converted to csv\n",
    "    path_directory: The directory where the dataframe has to be stored\n",
    "    \n",
    "    Output: None\n",
    "    \n",
    "    Function Description:\n",
    "    The function takes in a dataframe and the path directory to which the csv has to be generated\n",
    "    '''\n",
    "    df.to_csv(path_directory, index = False)\n",
    "    print(\"Successfully converted dataframe to csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa6bea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    '''\n",
    "    Function Description:\n",
    "    This is the main function where the final csv is created and all the functions are called\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ## Dataframe where the scrapped data is stored\n",
    "    df_scrapped_data = pd.DataFrame()\n",
    "    \n",
    "    ## Location of text file with the links which are to be scrapped\n",
    "    filepath = '/Users/abhishek_rajeev/Desktop/quinte/chakku/projects/Abhishek_WebScrapping/link.txt'\n",
    "    \n",
    "    ## While loop to loop over each link\n",
    "    with open(filepath) as fp:\n",
    "        line = fp.readline()\n",
    "        while line:\n",
    "            whisky = get_link(line.strip())\n",
    "            df_scrapped_data = df_scrapped_data.append(whisky, ignore_index=True)\n",
    "            time.sleep(5)\n",
    "            line = fp.readline()\n",
    "            \n",
    "    ## Name of the csv file\n",
    "    name_of_csv_file =  'scrapped_data.csv'\n",
    "    \n",
    "    ## Path location of the csv file\n",
    "    path_directory = f'/Users/abhishek_rajeev/Desktop/quinte/chakku/projects/Abhishek_WebScrapping/{name_of_csv_file}'\n",
    "    \n",
    "    ## Function that converts the dataframe to csv\n",
    "    convert_df_to_csv(df_scrapped_data,path_directory)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a7cba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f556f75b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
